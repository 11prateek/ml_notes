{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Family and Generalized Linear Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Family\n",
    "\n",
    "\n",
    "The exponential family is a set of probability distributions with very useful properties. A distribution from the exponential family has the form of:\n",
    "\n",
    "$$p(y \\ | \\ \\boldsymbol{\\theta}) = h(y) \\exp \\Big( \\displaystyle\\sum_i^s \\eta_i (\\boldsymbol{\\theta}) T_i(y) - A(\\boldsymbol{\\theta})\\Big) $$\n",
    "\n",
    "This distribution can be simplified by writing it in its canonical form by setting $\\boldsymbol{\\eta} (\\boldsymbol{\\theta}) = \\boldsymbol{\\theta}$:\n",
    "\n",
    "$$p(y \\ | \\ \\boldsymbol{\\eta}) = h(y) \\exp \\Big( \\displaystyle\\sum_i^s \\eta_i T_i(y) - A(\\boldsymbol{\\eta})\\Big) $$\n",
    "\n",
    "where the $T_i(y)$ are the sufficient statistics, $A(\\boldsymbol{\\eta})$ is the log-normalizer, $h(y)$ is the base-measure and $\\eta_i$ are the natural parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Examples\n",
    "\n",
    "### Bernoulli\n",
    "\n",
    "$$p(y \\ | \\ \\pi) = \\pi^{y} \\ (1-\\pi)^{1-y}$$\n",
    "\n",
    "where $y \\in \\{0, 1\\}$ and $\\pi \\in [0, 1]$.\n",
    "\n",
    "Take the exponential of the log density:\n",
    "\n",
    "\\begin{align}\n",
    "p(y \\ | \\ \\pi) &= \\exp \\Big( \\ln \\big(  \\pi^{y} \\ (1-\\pi)^{1-y} \\big) \\Big) \\\\\n",
    "& = \\exp \\Big( y \\ln (\\pi) + (1-y) \\ln(1-\\pi) \\Big) \\\\\n",
    "& = \\exp \\Big( y \\ln (\\frac{\\pi}{1-\\pi}) +  \\ln(1-\\pi) \\Big) \\\\\n",
    "\\end{align}\n",
    "\n",
    "* Sufficient statistic $T(y) = y$\n",
    "* Base measure $h(y) = 1$\n",
    "* Natural parameter $\\eta = \\ln (\\frac{\\pi}{1-\\pi})$\n",
    "* Log-normalizer $A(\\eta) = -\\ln(1-\\pi) = \\ln(1 + e^\\eta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian\n",
    "\n",
    "$$p(y \\ | \\ \\mu, \\ \\sigma) = \\frac{1}{\\sqrt{2 π \\sigma^2}} \\exp\\big({-\\frac{(y - \\mu)^2}{2 \\sigma^2}}\\big)$$\n",
    "\n",
    "where $y \\in \\mathbb{R}$, $\\mu \\in \\mathbb{R}$ and $\\sigma \\in \\mathbb{R}$.\n",
    "\n",
    "Take the exponential of the log density:\n",
    "\n",
    "\\begin{align}\n",
    "p(y \\ | \\ \\mu, \\ \\sigma) &= \\exp \\Big( \\ln \\big( \\frac{1}{\\sqrt{2 π \\sigma^2}}\\big) - \\frac{(y - \\mu)^2}{2 \\sigma^2}  \\Big)\\\\\n",
    "& = \\frac{1}{\\sqrt{2 π}} \\exp \\Big( \\frac{\\mu}{\\sigma^2} y - \\frac{1}{2 \\sigma^2} y^2 - \\frac{\\mu^2}{2 \\sigma^2}  - \\ln(\\sigma) \\Big)\n",
    "\\end{align}\n",
    "\n",
    "* Sufficient statistic $\\mathbf{T}(y) = [y, \\ y^2]^T$\n",
    "* Base measure $h(y) = \\frac{1}{\\sqrt{2 π}}$\n",
    "* Natural parameter $\\boldsymbol{\\eta} = [\\frac{\\mu}{\\sigma^2}, \\ \\frac{-1}{2 \\sigma^2}]^T$\n",
    "* Log-normalizer $A(\\eta) = \\frac{\\mu^2}{2 \\sigma^2} + \\ln(\\sigma)= -\\frac{\\eta_1^2}{4 \\eta_2} - \\frac{1}{2}\\ln(-2\\eta_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments of Log-Normalizer\n",
    "\n",
    "$$A(\\boldsymbol{\\eta}) = \\ln \\int h(y) \\exp \\Big( \\displaystyle\\sum_i^s \\eta_i T_i(y) \\Big) dy $$\n",
    "\n",
    "Taking the derivative w.r.t. $\\eta_i$:\n",
    "\n",
    "$$\\frac{\\partial A(\\boldsymbol{\\eta})}{\\partial \\eta_i} = \\frac{\\partial}{\\partial \\eta_i} \\ln \\int h(y) \\exp \\Big( \\displaystyle\\sum_i^s \\eta_i T_i(y) \\Big) dy = \\mathop{\\mathbb{E}}[T_i(y)]$$\n",
    "\n",
    "Taking the second-derivative gives:\n",
    "\n",
    "$$\\frac{\\partial^2 A(\\boldsymbol{\\eta})}{\\partial \\eta_j \\partial \\eta_i} = \\text{Cov}(T_i(y), T_j(y))$$\n",
    "\n",
    "The Hessian matrix of $A(\\boldsymbol{\\eta})$ is positive semi-definite. Proof:\n",
    "\n",
    "$$\\frac{\\partial^2 A(\\boldsymbol{\\eta})}{\\partial \\eta_j \\partial \\eta_i} = \\text{Cov}(T_i(y), T_j(y)) = \\mathop{\\mathbb{E}}[(T_i(y) - \\mathop{\\mathbb{E}}[T_i(y)])(T_j(y) - \\mathop{\\mathbb{E}}[T_j(y)])]$$\n",
    "\n",
    "For simplicity, let $C_{ij}$ = $\\text{Cov}(T_i(y), T_j(y))$ and $v_i$ = $T_i(y) - \\mathop{\\mathbb{E}}[T_i(y)]$:\n",
    "\n",
    "$$C_{ij} = \\mathop{\\mathbb{E}}[v_i v_j]$$\n",
    "\n",
    "For any vector $ \\mathbf{u}$:\n",
    "\n",
    "$$ \\mathbf{u}^T \\mathbf{C} \\mathbf{u} = \\sum_{ij} u_i C_{ij} u_j = \\sum_{ij} u_i\\mathop{\\mathbb{E}}[v_i v_j]u_j = \\mathop{\\mathbb{E}}[\\sum_{ij} u_iv_i v_ju_j] = \\mathop{\\mathbb{E}}[\\sum_{i} u_i v_i \\sum_{j} u_j v_j] = \\mathop{\\mathbb{E}}[(\\sum_{i} u_i v_i)^2] \\geq 0 $$\n",
    "\n",
    "Thus $A(\\boldsymbol{\\eta})$ is a convex function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "The likelihood function for $n$ samples drawn i.i.d. from an exponential distribution:\n",
    "$$p(y_1, y_2, ..., y_n \\ | \\ \\boldsymbol{\\eta}) = \\prod_j^n h(y_j) \\exp \\Big( \\displaystyle\\sum_i^s \\eta_i T_i(y_j) - A(\\boldsymbol{\\eta})\\Big) = \\exp \\Big( \\displaystyle\\sum_i^s \\eta_i \\displaystyle\\sum_j^n T_i(y_j) - n A(\\boldsymbol{\\eta})\\Big) \\prod_j^n h(y_j) $$\n",
    "\n",
    "Taking the negative log of the likelihood:\n",
    "\n",
    "$$\\mathcal{L} = n A(\\boldsymbol{\\eta}) - \\displaystyle\\sum_i^s \\eta_i \\displaystyle\\sum_j^n T_i(y_j) - \\sum_j^n \\ln h(y_j) $$\n",
    "\n",
    "The negative log-likelihood is convex as its Hessian is proportional to the Hessian of $A(\\boldsymbol{\\eta})$:\n",
    "\n",
    "$$\\frac{\\partial^2 \\mathcal{L}}{\\partial \\eta_j \\partial \\eta_i} = n  \\frac{\\partial^2 A(\\boldsymbol{\\eta}) }{\\partial \\eta_j \\partial \\eta_i}$$\n",
    "\n",
    "Therefore, to find the MLE, set the first derivative of the negative log-likelihood to $0$:\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\eta_i} = n  \\frac{\\partial A(\\boldsymbol{\\eta}) }{\\partial \\eta_i} -  \\displaystyle\\sum_j^n T_i(y_j) = 0$$\n",
    "\n",
    "Thus the MLE parameters $\\boldsymbol{\\eta}$ can be determined from the empirical mean of the sufficient statistic:\n",
    "\n",
    "$$\\frac{\\partial A(\\boldsymbol{\\eta}) }{\\partial \\eta_i} = \\frac{1}{n} \\displaystyle\\sum_j^n T_i(y_j)$$\n",
    "\n",
    "For Bernoulli, combining the above equation with previous results will give:\n",
    "\n",
    "$$\\pi_{MLE} = \\frac{1}{n} \\displaystyle\\sum_j^n y_j$$\n",
    "\n",
    "\n",
    "Similarly for Gaussian:\n",
    "\n",
    "$$\\mu_{MLE} = \\frac{1}{n} \\displaystyle\\sum_j^n y_j$$\n",
    "\n",
    "$$\\sigma^2_{MLE} = \\frac{1}{n} \\displaystyle\\sum_j^n (y_j - \\mu_{MLE})^2$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Linear Models\n",
    "\n",
    "Exponential families form the basis for GLMs. \n",
    "\n",
    "Represent the conditional expectation of $y_i$ as function $f$ of the linear combination of unknown parameters $\\mathbf{w}$ and features $\\mathbf{x_i}$:\n",
    "$$ \\mathop{\\mathbb{E}}[y_i \\ | \\ \\mathbf{x_i}] = f(\\mathbf{w}^T \\mathbf{x_i})$$\n",
    "\n",
    "where $f$ is known as the response function.\n",
    "\n",
    "The conditional expectation $f(\\mathbf{w}^T \\mathbf{x_i})$ is mapped to the natural parameter $\\eta_i = \\psi(f(\\mathbf{w}^T \\mathbf{x_i})) $. Thus the conditional distribution of $y_i$ takes the form: \n",
    "\n",
    "$$p(y_i \\ | \\ \\mathbf{x_i}) = h(y_i) \\exp \\Big( \\eta_i y_i - A(\\eta_i)\\Big) $$\n",
    "\n",
    "Here $T(y) = y$ as we want to focus on the distribution of $y$.\n",
    "\n",
    "The distribution can be simplified further by picking the canonical response $f(*) = \\psi^{-1}(*) $, which leads to  $\\eta_i = \\mathbf{w}^T \\mathbf{x_i} $   and:\n",
    "\n",
    "$$p(y_i \\ | \\ \\mathbf{x_i}) = h(y_i) \\exp \\Big( y_i \\mathbf{w}^T \\mathbf{x_i} - A(\\eta_i)\\Big) $$\n",
    "\n",
    "\n",
    "\n",
    "To be continued ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.stat.berkeley.edu/~mjwain/Fall2012_Stat241a/reader_ch8.pdf\n",
    "- https://en.wikipedia.org/wiki/Exponential_family\n",
    "- https://en.wikipedia.org/wiki/Generalized_linear_model\n",
    "- https://math.stackexchange.com/questions/114072/what-is-the-proof-that-covariance-matrices-are-always-semi-definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
